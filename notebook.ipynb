{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d4697ce0",
      "metadata": {
        "id": "d4697ce0"
      },
      "source": [
        "# Herpeton Project\n",
        "\n",
        "\n",
        "## Dataset Information\n",
        "- **Source**: [BGLab/BioTrove-Train on Hugging Face](https://huggingface.co/datasets/BGLab/BioTrove-Train)\n",
        "- **Focus**: Reptilia taxonomic class (snakes, lizards, turtles, etc.)\n",
        "- **Total Dataset Size**: ~135M samples across 7 taxonomic groups\n",
        "- **Estimated Reptilia Subset**: ~1.3M labeled reptile images across 189+ species\n",
        "- **Official Processing**: Uses `arbor_process` library for metadata preprocessing\n",
        "\n",
        "## Setup Requirements\n",
        "1. Install required packages\n",
        "2. Download metadata files from HuggingFace\n",
        "3. Process using official BioTrove tools\n",
        "4. Download images and create ML-ready dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89c60164",
      "metadata": {
        "id": "89c60164"
      },
      "source": [
        "# Pre-Work\n",
        "\n",
        "Depending upon how this notebook is run, compatability issues are likely to crop up, so this compatibility cell is here to solve for PyArrow issues encountered when first run."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3Iu6JjMQZx3",
        "outputId": "255e195e-2431-40bf-dbca-280448073323"
      },
      "id": "B3Iu6JjMQZx3",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: arbor-process in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 4)) (0.1.1)\n",
            "Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 12)) (10.3.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 13)) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 16)) (3.9.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 17)) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 20)) (4.66.4)\n",
            "Requirement already satisfied: requests>=2.28.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 23)) (2.32.4)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 26)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 27)) (0.23.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 28)) (4.57.1)\n",
            "Collecting jupyter>=1.0.0 (from -r /content/requirements.txt (line 31))\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.6.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 32)) (7.7.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 35)) (1.6.1)\n",
            "Requirement already satisfied: imageio>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 36)) (2.37.2)\n",
            "Requirement already satisfied: nest_asyncio>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 37)) (1.6.0)\n",
            "Requirement already satisfied: aiohttp==3.9.5 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (3.9.5)\n",
            "Requirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout==4.0.3 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: attrs==23.2.0 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: contourpy==1.2.1 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (1.2.1)\n",
            "Requirement already satisfied: cramjam==2.8.3 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (2.8.3)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fastparquet==2024.5.0 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (2024.5.0)\n",
            "Requirement already satisfied: fonttools==4.53.0 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (4.53.0)\n",
            "Requirement already satisfied: frozenlist==1.4.1 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: fsspec==2024.6.0 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (2024.6.0)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: importlib-resources==6.4.0 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (6.4.0)\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (1.4.5)\n",
            "Requirement already satisfied: multidict==6.0.5 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (6.0.5)\n",
            "Requirement already satisfied: packaging==24.1 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (24.1)\n",
            "Requirement already satisfied: pyarrow==16.1.0 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (16.1.0)\n",
            "Requirement already satisfied: pyparsing==3.1.2 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz==2024.1 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (2024.1)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: tzdata==2024.1 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (2024.1)\n",
            "Requirement already satisfied: yarl==1.9.4 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: zipp==3.19.2 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (3.19.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (3.20.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python>=4.5.0 (from -r /content/requirements.txt (line 13))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->-r /content/requirements.txt (line 23)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->-r /content/requirements.txt (line 23)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->-r /content/requirements.txt (line 23)) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.20.0->-r /content/requirements.txt (line 28)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.20.0->-r /content/requirements.txt (line 28)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.20.0->-r /content/requirements.txt (line 28)) (0.6.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (6.17.1)\n",
            "Collecting jupyterlab (from jupyter>=1.0.0->-r /content/requirements.txt (line 31))\n",
            "  Downloading jupyterlab-4.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (3.0.16)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->-r /content/requirements.txt (line 35)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->-r /content/requirements.txt (line 35)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->-r /content/requirements.txt (line 35)) (3.6.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=2.14.0->-r /content/requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (6.5.1)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (4.9.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.12.0->-r /content/requirements.txt (line 26)) (1.3.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (25.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (5.9.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (5.10.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.3.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.5.1)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31))\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.28.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31))\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.14.0)\n",
            "Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31))\n",
            "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.6.1->notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (4.5.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.9.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (25.1.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31))\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (4.25.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.21.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.2.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.28.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (4.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.1.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.23)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.4.0)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jupyterlab-4.5.0-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m134.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: opencv-python, json5, jedi, async-lru, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "Successfully installed async-lru-2.0.5 jedi-0.19.2 json5-0.12.1 jupyter-1.1.1 jupyter-lsp-2.3.0 jupyterlab-4.5.0 jupyterlab-server-2.28.0 opencv-python-4.11.0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python quick_start.py"
      ],
      "metadata": {
        "id": "W6XYfcohQi0c"
      },
      "id": "W6XYfcohQi0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c1e2cd2e",
      "metadata": {
        "id": "c1e2cd2e",
        "outputId": "7d9c4f7b-01df-49fa-e82c-709a9a7d8143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up BioTrove Reptilia processing environment...\n",
            "============================================================\n",
            "Checking PyArrow compatibility...\n",
            "PyArrow version: 18.1.0\n",
            "PyExtensionType is available\n",
            "\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4058257925.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mall_installed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpackage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequired_packages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minstall_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mall_installed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4058257925.py\u001b[0m in \u001b[0;36minstall_package\u001b[0;34m(package_name, import_name)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Try to import the package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimport_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{package_name} is already installed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/arbor_process/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgen_filtered_shuffled_chunks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenShuffledChunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetadata_processor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetadataProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mget_imgs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGetImages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgen_img_txt_pair\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenImgTxtPair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mplotting_func\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/arbor_process/gen_filtered_shuffled_chunks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "# Install and address any PyArrow compatibility issues\n",
        "import subprocess\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "def check_and_fix_pyarrow():\n",
        "    \"\"\"Check PyArrow version and fix compatibility issues\"\"\"\n",
        "    print(\"Checking PyArrow compatibility...\")\n",
        "\n",
        "    try:\n",
        "        import pyarrow as pa\n",
        "        print(f\"PyArrow version: {pa.__version__}\")\n",
        "\n",
        "        # Test for the extension type attribute\n",
        "        if hasattr(pa.lib, 'PyExtensionType'):\n",
        "            print(\"PyExtensionType is available\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"PyExtensionType not found - version issue detected\")\n",
        "            return False\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"PyArrow not installed\")\n",
        "        return False\n",
        "\n",
        "def fix_pyarrow_compatibility():\n",
        "    \"\"\"Fix PyArrow version compatibility\"\"\"\n",
        "    print(\"\\nFixing PyArrow compatibility...\")\n",
        "\n",
        "    try:\n",
        "        # Uninstall and reinstall with specific compatible versions if needed\n",
        "        print(\"Uninstalling existing PyArrow...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"pyarrow\"])\n",
        "\n",
        "        print(\"Installing compatible PyArrow version...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pyarrow>=12.0.0,<15.0.0\"])\n",
        "\n",
        "        # Ensure pandas compatibility\n",
        "        print(\"Updating pandas for compatibility...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pandas>=1.5.0\"])\n",
        "\n",
        "        print(\"PyArrow compatibility fix complete!\")\n",
        "        return True\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Failed to fix PyArrow: {e}\")\n",
        "        return False\n",
        "\n",
        "def install_package(package_name, import_name=None):\n",
        "    \"\"\"Install a package and verify it can be imported\"\"\"\n",
        "    if import_name is None:\n",
        "        import_name = package_name\n",
        "\n",
        "    try:\n",
        "        # Try to import the package\n",
        "        importlib.import_module(import_name)\n",
        "        print(f\"{package_name} is already installed\")\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"Installing {package_name}...\")\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "            print(f\"{package_name} installed successfully\")\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Failed to install {package_name}: {e}\")\n",
        "            return False\n",
        "\n",
        "print(\"Setting up BioTrove Reptilia processing environment...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check and fix PyArrow if needed\n",
        "if not check_and_fix_pyarrow():\n",
        "    print(\"\\nAttempting to fix PyArrow compatibility...\")\n",
        "    if fix_pyarrow_compatibility():\n",
        "        # Re-check after fix\n",
        "        if check_and_fix_pyarrow():\n",
        "            print(\"PyArrow issue resolved!\")\n",
        "        else:\n",
        "            print(\"WARNING: PyArrow issue persists\")\n",
        "    else:\n",
        "        print(\"ERROR: Could not automatically fix PyArrow\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# List of required packages (with specific versions to avoid conflicts)\n",
        "required_packages = [\n",
        "    (\"arbor-process\", \"arbor_process\"),\n",
        "    (\"nest_asyncio\", \"nest_asyncio\"),\n",
        "    (\"datasets>=2.14.0\", \"datasets\"),\n",
        "    (\"pandas>=1.5.0\", \"pandas\"),\n",
        "    (\"numpy\", \"numpy\"),\n",
        "    (\"matplotlib\", \"matplotlib\"),\n",
        "    (\"seaborn\", \"seaborn\"),\n",
        "    (\"pillow\", \"PIL\"),\n",
        "    (\"requests\", \"requests\"),\n",
        "    (\"tqdm\", \"tqdm\")\n",
        "]\n",
        "\n",
        "# Install packages\n",
        "all_installed = True\n",
        "for package_name, import_name in required_packages:\n",
        "    if not install_package(package_name, import_name):\n",
        "        all_installed = False\n",
        "\n",
        "if all_installed:\n",
        "    print(\"\\nAll packages installed successfully\")\n",
        "    print(\"Ready to process BioTrove Reptilia dataset\")\n",
        "else:\n",
        "    print(\"\\nWARNING: Some packages failed to install\")\n",
        "    print(\"You may need to install them manually\")\n",
        "\n",
        "print(\"\\nNOTE: If PyArrow errors persist, try:\")\n",
        "print(\"   pip install --force-reinstall pyarrow==14.0.2\")\n",
        "print(\"   pip install --force-reinstall pandas==2.0.3\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "639411f7",
      "metadata": {
        "id": "639411f7"
      },
      "source": [
        "## Step 1: Extract Reptilia Metadata from BioTrove\n",
        "\n",
        "Using HuggingFace's efficient filter() method to extract only Reptilia samples from the 135M sample dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7795bf7f",
      "metadata": {
        "id": "7795bf7f"
      },
      "outputs": [],
      "source": [
        "def extract_reptilia_efficient():\n",
        "    \"\"\"\n",
        "    Efficiently extract Reptilia samples using HuggingFace datasets with filtering.\n",
        "    Since Reptilia exists in the dataset but is distributed throughout 135M samples,\n",
        "    the dataset's built-in filtering capabilities are used.\n",
        "    \"\"\"\n",
        "    from datasets import load_dataset\n",
        "    from tqdm.auto import tqdm\n",
        "\n",
        "    print(\"EFFICIENT REPTILIA EXTRACTION\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Using filter() to extract only Reptilia class\")\n",
        "\n",
        "\n",
        "    # Load dataset in streaming mode\n",
        "    print(\"Loading BioTrove-Train dataset...\")\n",
        "    dataset = load_dataset('BGLab/BioTrove-Train', streaming=True, split='train')\n",
        "\n",
        "    # Filter for Reptilia class\n",
        "    print(\"Applying Reptilia filter...\")\n",
        "    reptilia_dataset = dataset.filter(lambda example: example['class'] == 'Reptilia')\n",
        "\n",
        "    print(\"Extracting Reptilia samples...\")\n",
        "    reptilia_samples = []\n",
        "\n",
        "    pbar = tqdm(desc=\"Collecting Reptilia\", unit=\" samples\")\n",
        "\n",
        "    # Collect samples\n",
        "    target_samples = 2000  # Collect 2000 Reptilia samples\n",
        "\n",
        "    for idx, item in enumerate(reptilia_dataset):\n",
        "        reptilia_samples.append(item)\n",
        "\n",
        "        if idx < 10:  # Show first 10\n",
        "            print(f\"\\n   Sample {idx+1}:\")\n",
        "            print(f\"      scientificName: {item.get('scientificName', 'Unknown')}\")\n",
        "            print(f\"      family: {item.get('family', 'Unknown')}\")\n",
        "            print(f\"      order: {item.get('order', 'Unknown')}\")\n",
        "\n",
        "        pbar.update(1)\n",
        "        pbar.set_description(f\"Collected {len(reptilia_samples)} Reptilia\")\n",
        "\n",
        "        if len(reptilia_samples) >= target_samples:\n",
        "            print(f\"\\n   Reached target of {target_samples} samples\")\n",
        "            break\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXTRACTION COMPLETE:\")\n",
        "    print(f\"   Total Reptilia samples collected: {len(reptilia_samples)}\")\n",
        "\n",
        "    if reptilia_samples:\n",
        "        # Save to parquet chunks\n",
        "        os.makedirs(\"biotrove_metadata\", exist_ok=True)\n",
        "        chunk_size = 250\n",
        "        saved_files = []\n",
        "\n",
        "        print(f\"\\n   Saving {len(reptilia_samples)} samples in chunks of {chunk_size}...\")\n",
        "\n",
        "        for i in range(0, len(reptilia_samples), chunk_size):\n",
        "            chunk_data = reptilia_samples[i:i+chunk_size]\n",
        "            chunk_df = pd.DataFrame(chunk_data)\n",
        "\n",
        "            chunk_filename = f\"biotrove_metadata/reptilia_chunk_{i//chunk_size}.parquet\"\n",
        "            chunk_df.to_parquet(chunk_filename, index=False)\n",
        "            saved_files.append(chunk_filename)\n",
        "\n",
        "            print(f\"      Chunk {i//chunk_size}: {len(chunk_data)} samples -> {chunk_filename}\")\n",
        "\n",
        "        print(f\"\\n   ✓ Saved {len(saved_files)} parquet files\")\n",
        "\n",
        "        # Show species diversity\n",
        "        species_list = [s.get('scientificName', 'Unknown') for s in reptilia_samples]\n",
        "        unique_species = set(species_list)\n",
        "        print(f\"   ✓ {len(unique_species)} unique species\")\n",
        "\n",
        "        # Show top families\n",
        "        families = [s.get('family', 'Unknown') for s in reptilia_samples]\n",
        "        from collections import Counter\n",
        "        top_families = Counter(families).most_common(10)\n",
        "        print(f\"\\n   Top 10 families:\")\n",
        "        for family, count in top_families:\n",
        "            print(f\"      {family}: {count} samples\")\n",
        "\n",
        "        return {\n",
        "            'samples': reptilia_samples,\n",
        "            'saved_files': saved_files,\n",
        "            'unique_species': len(unique_species)\n",
        "        }\n",
        "    else:\n",
        "        print(\"   ✗ No Reptilia samples found\")\n",
        "        return None\n",
        "\n",
        "# Run the efficient extraction\n",
        "reptilia_data = extract_reptilia_efficient()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6522339e",
      "metadata": {
        "id": "6522339e"
      },
      "source": [
        "## Step 2: Verify Extracted Data\n",
        "\n",
        "Check the extracted Reptilia samples before processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "abb4e775",
      "metadata": {
        "id": "abb4e775",
        "outputId": "6b3d1a5f-9306-48a7-b24d-080c1be3fed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VERIFICATION: Extracted Reptilia Data\n",
            "============================================================\n",
            "Found 0 parquet chunk files:\n",
            "\n",
            "Loading all Reptilia data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2033660690.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nLoading all Reptilia data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mall_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mreptilia_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTOTAL REPTILIA DATASET:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# Verify the extracted Reptilia data\n",
        "import glob\n",
        "\n",
        "print(\"VERIFICATION: Extracted Reptilia Data\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Find all reptilia chunk files\n",
        "chunk_files = sorted(glob.glob(\"biotrove_metadata/reptilia_chunk_*.parquet\"))\n",
        "\n",
        "print(f\"Found {len(chunk_files)} parquet chunk files:\")\n",
        "for file in chunk_files:\n",
        "    df = pd.read_parquet(file)\n",
        "    print(f\"   {file}: {len(df)} samples\")\n",
        "\n",
        "# Load all chunks\n",
        "print(\"\\nLoading all Reptilia data...\")\n",
        "all_dfs = [pd.read_parquet(f) for f in chunk_files]\n",
        "reptilia_df = pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "print(f\"\\nTOTAL REPTILIA DATASET:\")\n",
        "print(f\"   Total samples: {len(reptilia_df):,}\")\n",
        "print(f\"   Unique species: {reptilia_df['scientificName'].nunique()}\")\n",
        "print(f\"   Unique families: {reptilia_df['family'].nunique()}\")\n",
        "print(f\"   Unique orders: {reptilia_df['order'].nunique()}\")\n",
        "\n",
        "print(f\"\\nCOLUMNS:\")\n",
        "print(f\"   {list(reptilia_df.columns)}\")\n",
        "\n",
        "print(f\"\\nORDER DISTRIBUTION:\")\n",
        "order_counts = reptilia_df['order'].value_counts()\n",
        "for order, count in order_counts.items():\n",
        "    print(f\"   {order}: {count} samples ({count/len(reptilia_df)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nTOP 15 SPECIES:\")\n",
        "species_counts = reptilia_df['scientificName'].value_counts().head(15)\n",
        "for species, count in species_counts.items():\n",
        "    family = reptilia_df[reptilia_df['scientificName'] == species]['family'].iloc[0]\n",
        "    print(f\"   {species:<40} ({family:<20}): {count} samples\")\n",
        "\n",
        "print(f\"\\nFIRST 3 SAMPLE ROWS:\")\n",
        "print(reptilia_df.head(3).to_string(index=False))\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"✓ Reptilia dataset successfully extracted and verified!\")\n",
        "print(\"✓ Ready for BioTrove processing pipeline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f89dac30",
      "metadata": {
        "id": "f89dac30"
      },
      "source": [
        "## Step 3: Download Images and Create Dataset\n",
        "\n",
        "Download images from URLs and create ML-ready dataset with image-text pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11c4cdac",
      "metadata": {
        "id": "11c4cdac"
      },
      "outputs": [],
      "source": [
        "# Install arbor_process library for BioTrove processing\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import arbor_process\n",
        "    print(\"arbor_process is already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing arbor_process library...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"arbor-process\"])\n",
        "    import arbor_process\n",
        "    print(\"Successfully installed arbor_process\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64aea5b1",
      "metadata": {
        "id": "64aea5b1"
      },
      "outputs": [],
      "source": [
        "# Download Reptilia images from metadata URLs\n",
        "import os\n",
        "import glob\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "print(\"REPTILIA IMAGE DOWNLOAD\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(\"biotrove_processed\", exist_ok=True)\n",
        "os.makedirs(\"biotrove_processed/images\", exist_ok=True)\n",
        "\n",
        "# Load all Reptilia chunks\n",
        "chunk_files = sorted(glob.glob(\"biotrove_metadata/reptilia_chunk_*.parquet\"))\n",
        "print(f\"Loading {len(chunk_files)} Reptilia parquet chunks...\")\n",
        "\n",
        "all_chunks = [pd.read_parquet(f) for f in chunk_files]\n",
        "reptilia_metadata = pd.concat(all_chunks, ignore_index=True)\n",
        "\n",
        "print(f\"Total Reptilia samples: {len(reptilia_metadata):,}\")\n",
        "print(f\"Unique species: {reptilia_metadata['scientificName'].nunique()}\")\n",
        "\n",
        "# Save combined metadata\n",
        "metadata_path = \"biotrove_processed/reptilia_metadata.csv\"\n",
        "reptilia_metadata.to_csv(metadata_path, index=False)\n",
        "print(f\"\\nSaved combined metadata to: {metadata_path}\")\n",
        "\n",
        "def download_image(row):\n",
        "    \"\"\"Download a single image from URL\"\"\"\n",
        "    photo_id = row['photo_id']\n",
        "    \"\"\"Download single image from URL\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(photo_url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Open and verify image\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "\n",
        "        # Save image\n",
        "        img_filename = f\"biotrove_processed/images/{photo_id}.jpg\"\n",
        "        img.convert('RGB').save(img_filename, 'JPEG', quality=95)\n",
        "\n",
        "        return {'photo_id': photo_id, 'status': 'success', 'path': img_filename}\n",
        "    except Exception as e:\n",
        "        return {'photo_id': photo_id, 'status': 'failed', 'error': str(e)}\n",
        "\n",
        "# Download images with parallel processing\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DOWNLOADING IMAGES\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Downloading {len(reptilia_metadata)} images with 4 parallel workers...\")\n",
        "\n",
        "successful_downloads = []\n",
        "failed_downloads = []\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    # Submit all download tasks\n",
        "    futures = {executor.submit(download_image, row): idx\n",
        "               for idx, row in reptilia_metadata.iterrows()}\n",
        "\n",
        "    # Process completed downloads with progress bar\n",
        "    with tqdm(total=len(futures), desc=\"Downloading\") as pbar:\n",
        "        for future in as_completed(futures):\n",
        "            result = future.result()\n",
        "\n",
        "            if result['status'] == 'success':\n",
        "                successful_downloads.append(result)\n",
        "            else:\n",
        "                failed_downloads.append(result)\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_description(f\"Downloaded: {len(successful_downloads)}, Failed: {len(failed_downloads)}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"DOWNLOAD COMPLETE!\")\n",
        "print(f\"  Successfully downloaded: {len(successful_downloads)} images\")\n",
        "print(f\"  Failed downloads: {len(failed_downloads)} images\")\n",
        "print(f\"  Success rate: {len(successful_downloads)/len(reptilia_metadata)*100:.1f}%\")\n",
        "\n",
        "# Create image-text pairs dataset\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATING IMAGE-TEXT PAIRS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "successful_photo_ids = [d['photo_id'] for d in successful_downloads]\n",
        "successful_metadata = reptilia_metadata[reptilia_metadata['photo_id'].isin(successful_photo_ids)].copy()\n",
        "\n",
        "# Add image paths\n",
        "successful_metadata['image_path'] = successful_metadata['photo_id'].apply(\n",
        "    lambda x: f\"biotrove_processed/images/{x}.jpg\"\n",
        ")\n",
        "\n",
        "# Create text descriptions\n",
        "successful_metadata['text_description'] = successful_metadata.apply(\n",
        "    lambda row: f\"{row['scientificName']} ({row['common_name']}) - {row['family']}, Order {row['order']}, Class Reptilia\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Save final dataset\n",
        "final_dataset_path = \"biotrove_processed/reptilia_dataset_final.csv\"\n",
        "successful_metadata.to_csv(final_dataset_path, index=False)\n",
        "\n",
        "print(f\"Created {len(successful_metadata)} image-text pairs\")\n",
        "print(f\"Saved to: {final_dataset_path}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"PROCESSING COMPLETE!\")\n",
        "print(f\"  Metadata: {metadata_path}\")\n",
        "print(f\"  Images: biotrove_processed/images/ ({len(successful_downloads)} files)\")\n",
        "print(f\"  Final dataset: {final_dataset_path}\")\n",
        "print(f\"  Dataset ready for computer vision training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d0f896",
      "metadata": {
        "id": "30d0f896"
      },
      "outputs": [],
      "source": [
        "# Explore the processed dataset\n",
        "import random\n",
        "\n",
        "print(\"PROCESSED DATASET EXPLORATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check directory structure\n",
        "print(\"\\nDirectory structure:\")\n",
        "for root, dirs, files in os.walk(\"biotrove_processed\"):\n",
        "    level = root.replace(\"biotrove_processed\", \"\").count(os.sep)\n",
        "    indent = \" \" * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = \" \" * 2 * (level + 1)\n",
        "    for file in files[:5]:  # Show first 5 files\n",
        "        print(f\"{subindent}{file}\")\n",
        "    if len(files) > 5:\n",
        "        print(f\"{subindent}... and {len(files)-5} more files\")\n",
        "\n",
        "# Load processed metadata\n",
        "if os.path.exists(\"biotrove_processed/metadata.csv\"):\n",
        "    processed_df = pd.read_csv(\"biotrove_processed/metadata.csv\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"PROCESSED DATASET STATISTICS:\")\n",
        "    print(f\"  Total samples: {len(processed_df):,}\")\n",
        "    print(f\"  Unique species: {processed_df['scientificName'].nunique()}\")\n",
        "    print(f\"  Unique families: {processed_df['family'].nunique()}\")\n",
        "    print(f\"  Unique orders: {processed_df['order'].nunique()}\")\n",
        "\n",
        "    print(f\"\\nOrder distribution:\")\n",
        "    for order, count in processed_df['order'].value_counts().items():\n",
        "        print(f\"  {order}: {count} samples ({count/len(processed_df)*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nTop 10 species:\")\n",
        "    for species, count in processed_df['scientificName'].value_counts().head(10).items():\n",
        "        print(f\"  {species}: {count} samples\")\n",
        "\n",
        "    # Show sample images if available\n",
        "    image_dir = \"biotrove_processed/images\"\n",
        "    if os.path.exists(image_dir):\n",
        "        image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if image_files:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Sample images available: {len(image_files)}\")\n",
        "\n",
        "            # Display a few random samples\n",
        "            sample_images = random.sample(image_files, min(3, len(image_files)))\n",
        "            print(f\"\\nDisplaying {len(sample_images)} random samples...\")\n",
        "\n",
        "            for img_file in sample_images:\n",
        "                img_path = os.path.join(image_dir, img_file)\n",
        "                # Get metadata for this image\n",
        "                img_id = os.path.splitext(img_file)[0]\n",
        "                if img_id.isdigit():\n",
        "                    sample_info = processed_df[processed_df['photo_id'] == int(img_id)]\n",
        "                    if not sample_info.empty:\n",
        "                        print(f\"\\n  Image: {img_file}\")\n",
        "                        print(f\"    Species: {sample_info.iloc[0]['scientificName']}\")\n",
        "                        print(f\"    Family: {sample_info.iloc[0]['family']}\")\n",
        "                        print(f\"    Common name: {sample_info.iloc[0].get('common_name', 'N/A')}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Dataset ready for computer vision training.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}