{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AAI-521 Group 6 Group Project"
      ],
      "metadata": {
        "id": "M-5CBNxOwhKO"
      },
      "id": "M-5CBNxOwhKO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# herpeton"
      ],
      "metadata": {
        "id": "9sZEOgrrwrFA"
      },
      "id": "9sZEOgrrwrFA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab Friendly Notebook"
      ],
      "metadata": {
        "id": "acgPwAwdYa4B"
      },
      "id": "acgPwAwdYa4B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Environment Setup"
      ],
      "metadata": {
        "id": "wbQ7YMbmCT9w"
      },
      "id": "wbQ7YMbmCT9w"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1a) Environment Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import hashlib\n",
        "import io\n",
        "import os\n",
        "import sys\n",
        "from collections import Counter, defaultdict\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Iterable, Optional, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "!pip install imagehash\n",
        "import imagehash\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Show plots inline\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install squarify > /dev/null\n",
        "import squarify\n",
        "\n",
        "!pip install plotly > /dev/null\n",
        "import plotly.express as px\n",
        "\n",
        "!pip install wordcloud > /dev/null\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "P5JEs1ktYJVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c04560c-77c5-4888-83bd-5b32dd1e1577"
      },
      "id": "P5JEs1ktYJVr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting PyWavelets (from imagehash)\n",
            "  Downloading pywavelets-1.9.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from imagehash) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from imagehash) (12.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from imagehash) (1.16.3)\n",
            "Downloading ImageHash-4.3.2-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/296.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.9.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m144.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets, imagehash\n",
            "Successfully installed PyWavelets-1.9.0 imagehash-4.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1b) Mount Google Drive\n",
        "CURATE_TO_DRIVE = True\n",
        "\n",
        "if CURATE_TO_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_OUT = \"/content/drive/MyDrive/herpeton/data/biotrove_train\"\n",
        "else:\n",
        "    BASE_OUT = \"/content/herpeton\"\n",
        "\n",
        "os.makedirs(BASE_OUT, exist_ok=True)\n",
        "\n",
        "# Controls to keep runtime reasonable\n",
        "#MAX_RECORDS = 15000          # hard cap across the stream (increase if you have time/compute)\n",
        "#SAMPLE_PER_SPECIES = 50      # images per species to collect/curate/EDA\n",
        "REPORT_DIR = os.path.join(BASE_OUT, \"_reports\")\n",
        "os.makedirs(REPORT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Output base: {BASE_OUT}\")\n",
        "print(f\"Reports   : {REPORT_DIR}\")\n",
        "#print(f\"Limits    : MAX_RECORDS={MAX_RECORDS}, SAMPLE_PER_SPECIES={SAMPLE_PER_SPECIES}\")"
      ],
      "metadata": {
        "id": "jEsm8rUUYW-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b25aee4-472e-4006-e03b-814055bd279f"
      },
      "id": "jEsm8rUUYW-3",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Output base: /content/drive/MyDrive/herpeton/data/biotrove_train\n",
            "Reports   : /content/drive/MyDrive/herpeton/data/biotrove_train/_reports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 Models"
      ],
      "metadata": {
        "id": "krNsKsAZumnF"
      },
      "id": "krNsKsAZumnF"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5a) Environment Setup\n",
        "!pip -q install timm\n",
        "\n",
        "import os\n",
        "import math\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import amp\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import timm\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "id": "aD1DPhihv2EM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e309615b-72bf-4d3b-b5c0-6bbb68738b2d"
      },
      "id": "aD1DPhihv2EM",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5b) Mount Drive & Load Metadata\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "metadata_path = (\n",
        "    \"/content/drive/MyDrive/herpeton//data (1)/biotrove_train/reptilia_dataset_processed.csv\"\n",
        ")\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/herpeton//data (1)/biotrove_train\"\n",
        "IMG_DIR = os.path.join(BASE_PATH, \"images_reptilia\")\n",
        "\n",
        "\n",
        "df = pd.read_csv(metadata_path)\n",
        "print(\"Metadata shape:\", df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "r9JvteR_wwYK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "34e2b702-45eb-42aa-c833-99173489b2df"
      },
      "id": "r9JvteR_wwYK",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Metadata shape: (18750, 16)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   photo_id           scientificName   kingdom    phylum     class     order  \\\n",
              "0    483440  Agkistrodon laticinctus  Animalia  Chordata  Reptilia  Squamata   \n",
              "1    345778     Sceloporus uniformis  Animalia  Chordata  Reptilia  Squamata   \n",
              "2    181353   Pantherophis spiloides  Animalia  Chordata  Reptilia  Squamata   \n",
              "3     35083  Lampropeltis triangulum  Animalia  Chordata  Reptilia  Squamata   \n",
              "4    261176        Imantodes cenchoa  Animalia  Chordata  Reptilia  Squamata   \n",
              "\n",
              "            family         genus      species                 common_name  \\\n",
              "0        Viperidae   Agkistrodon  laticinctus     Broad-banded Copperhead   \n",
              "1  Phrynosomatidae    Sceloporus    uniformis  Yellow-backed Spiny Lizard   \n",
              "2       Colubridae  Pantherophis    spiloides               Gray Ratsnake   \n",
              "3       Colubridae  Lampropeltis   triangulum           Eastern Milksnake   \n",
              "4       Colubridae     Imantodes      cenchoa        Blunthead Tree Snake   \n",
              "\n",
              "  taxonRank                                          photo_url  split  \\\n",
              "0   species  http://inaturalist-open-data.s3.amazonaws.com/...  train   \n",
              "1   species  http://inaturalist-open-data.s3.amazonaws.com/...  train   \n",
              "2   species  http://inaturalist-open-data.s3.amazonaws.com/...  train   \n",
              "3   species  http://inaturalist-open-data.s3.amazonaws.com/...  train   \n",
              "4   species  http://inaturalist-open-data.s3.amazonaws.com/...  train   \n",
              "\n",
              "                                    image_path_fixed  width  height  \n",
              "0  /content/drive/MyDrive/herpeton/data/biotrove_...  480.0   358.0  \n",
              "1  /content/drive/MyDrive/herpeton/data/biotrove_...  500.0   353.0  \n",
              "2  /content/drive/MyDrive/herpeton/data/biotrove_...  373.0   500.0  \n",
              "3  /content/drive/MyDrive/herpeton/data/biotrove_...  500.0   376.0  \n",
              "4  /content/drive/MyDrive/herpeton/data/biotrove_...  500.0   337.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15c805da-0219-4154-b719-1a83dd7564fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>photo_id</th>\n",
              "      <th>scientificName</th>\n",
              "      <th>kingdom</th>\n",
              "      <th>phylum</th>\n",
              "      <th>class</th>\n",
              "      <th>order</th>\n",
              "      <th>family</th>\n",
              "      <th>genus</th>\n",
              "      <th>species</th>\n",
              "      <th>common_name</th>\n",
              "      <th>taxonRank</th>\n",
              "      <th>photo_url</th>\n",
              "      <th>split</th>\n",
              "      <th>image_path_fixed</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>483440</td>\n",
              "      <td>Agkistrodon laticinctus</td>\n",
              "      <td>Animalia</td>\n",
              "      <td>Chordata</td>\n",
              "      <td>Reptilia</td>\n",
              "      <td>Squamata</td>\n",
              "      <td>Viperidae</td>\n",
              "      <td>Agkistrodon</td>\n",
              "      <td>laticinctus</td>\n",
              "      <td>Broad-banded Copperhead</td>\n",
              "      <td>species</td>\n",
              "      <td>http://inaturalist-open-data.s3.amazonaws.com/...</td>\n",
              "      <td>train</td>\n",
              "      <td>/content/drive/MyDrive/herpeton/data/biotrove_...</td>\n",
              "      <td>480.0</td>\n",
              "      <td>358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>345778</td>\n",
              "      <td>Sceloporus uniformis</td>\n",
              "      <td>Animalia</td>\n",
              "      <td>Chordata</td>\n",
              "      <td>Reptilia</td>\n",
              "      <td>Squamata</td>\n",
              "      <td>Phrynosomatidae</td>\n",
              "      <td>Sceloporus</td>\n",
              "      <td>uniformis</td>\n",
              "      <td>Yellow-backed Spiny Lizard</td>\n",
              "      <td>species</td>\n",
              "      <td>http://inaturalist-open-data.s3.amazonaws.com/...</td>\n",
              "      <td>train</td>\n",
              "      <td>/content/drive/MyDrive/herpeton/data/biotrove_...</td>\n",
              "      <td>500.0</td>\n",
              "      <td>353.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>181353</td>\n",
              "      <td>Pantherophis spiloides</td>\n",
              "      <td>Animalia</td>\n",
              "      <td>Chordata</td>\n",
              "      <td>Reptilia</td>\n",
              "      <td>Squamata</td>\n",
              "      <td>Colubridae</td>\n",
              "      <td>Pantherophis</td>\n",
              "      <td>spiloides</td>\n",
              "      <td>Gray Ratsnake</td>\n",
              "      <td>species</td>\n",
              "      <td>http://inaturalist-open-data.s3.amazonaws.com/...</td>\n",
              "      <td>train</td>\n",
              "      <td>/content/drive/MyDrive/herpeton/data/biotrove_...</td>\n",
              "      <td>373.0</td>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35083</td>\n",
              "      <td>Lampropeltis triangulum</td>\n",
              "      <td>Animalia</td>\n",
              "      <td>Chordata</td>\n",
              "      <td>Reptilia</td>\n",
              "      <td>Squamata</td>\n",
              "      <td>Colubridae</td>\n",
              "      <td>Lampropeltis</td>\n",
              "      <td>triangulum</td>\n",
              "      <td>Eastern Milksnake</td>\n",
              "      <td>species</td>\n",
              "      <td>http://inaturalist-open-data.s3.amazonaws.com/...</td>\n",
              "      <td>train</td>\n",
              "      <td>/content/drive/MyDrive/herpeton/data/biotrove_...</td>\n",
              "      <td>500.0</td>\n",
              "      <td>376.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>261176</td>\n",
              "      <td>Imantodes cenchoa</td>\n",
              "      <td>Animalia</td>\n",
              "      <td>Chordata</td>\n",
              "      <td>Reptilia</td>\n",
              "      <td>Squamata</td>\n",
              "      <td>Colubridae</td>\n",
              "      <td>Imantodes</td>\n",
              "      <td>cenchoa</td>\n",
              "      <td>Blunthead Tree Snake</td>\n",
              "      <td>species</td>\n",
              "      <td>http://inaturalist-open-data.s3.amazonaws.com/...</td>\n",
              "      <td>train</td>\n",
              "      <td>/content/drive/MyDrive/herpeton/data/biotrove_...</td>\n",
              "      <td>500.0</td>\n",
              "      <td>337.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15c805da-0219-4154-b719-1a83dd7564fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-15c805da-0219-4154-b719-1a83dd7564fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-15c805da-0219-4154-b719-1a83dd7564fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9de1ccb3-7879-492b-97d2-8e415f4f8edc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9de1ccb3-7879-492b-97d2-8e415f4f8edc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9de1ccb3-7879-492b-97d2-8e415f4f8edc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 18750,\n  \"fields\": [\n    {\n      \"column\": \"photo_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26703345,\n        \"min\": 27,\n        \"max\": 357056132,\n        \"num_unique_values\": 18750,\n        \"samples\": [\n          2318831,\n          189512,\n          852333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scientificName\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 531,\n        \"samples\": [\n          \"Elaphe climacophora\",\n          \"Porthidium nasutum\",\n          \"Anolis mccraniei\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kingdom\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Animalia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phylum\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Chordata\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Reptilia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Squamata\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 53,\n        \"samples\": [\n          \"Leiocephalidae\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genus\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 266,\n        \"samples\": [\n          \"Tropidolaemus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 528,\n        \"samples\": [\n          \"grahamii\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"common_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 529,\n        \"samples\": [\n          \"Metallic Coolskink\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"taxonRank\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"species\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"photo_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18750,\n        \"samples\": [\n          \"http://inaturalist-open-data.s3.amazonaws.com/photos/2318831/medium.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path_fixed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17614,\n        \"samples\": [\n          \"/content/drive/MyDrive/herpeton/data/biotrove_train/images_reptilia/processed_chunks_0005/38416881.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62.982622238607675,\n        \"min\": 122.0,\n        \"max\": 500.0,\n        \"num_unique_values\": 277,\n        \"samples\": [\n          160.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74.08432620513489,\n        \"min\": 63.0,\n        \"max\": 500.0,\n        \"num_unique_values\": 348,\n        \"samples\": [\n          438.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5c) Encode Labels & Train/Val Split\n",
        "# Use 'species' as label\n",
        "assert \"species\" in df.columns, \"Expected 'species' column in metadata.\"\n",
        "assert \"image_path_fixed\" in df.columns, \"Expected 'image_path_fixed' column with image paths.\"\n",
        "\n",
        "# Encode species as integer labels\n",
        "df[\"label_id\"], label_names = pd.factorize(df[\"species\"])\n",
        "num_classes = len(label_names)\n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n",
        "# Split data using the 'split' column\n",
        "train_df = df[df[\"split\"] == \"train\"].copy()\n",
        "val_df = df[df[\"split\"] == \"val\"].copy()\n",
        "test_df = df[df[\"split\"] == \"test\"].copy()\n",
        "\n",
        "# Filter out rows with NaN in 'image_path_fixed' column for each split\n",
        "train_df = train_df.dropna(subset=['image_path_fixed']).reset_index(drop=True)\n",
        "val_df = val_df.dropna(subset=['image_path_fixed']).reset_index(drop=True)\n",
        "test_df = test_df.dropna(subset=['image_path_fixed']).reset_index(drop=True)\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Val size:\", len(val_df))\n",
        "print(\"Test size:\", len(test_df))"
      ],
      "metadata": {
        "id": "AYzCaoC1zqKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a0860a-a050-49fa-eab8-f6ec9b0e2428"
      },
      "id": "AYzCaoC1zqKg",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 528\n",
            "Train size: 13879\n",
            "Val size: 1982\n",
            "Test size: 1753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5d) Dataset & Transforms\n",
        "class ReptiliaDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row[\"image_path_fixed\"]\n",
        "        label = int(row[\"label_id\"])\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "# Image size compatible with ResNet50\n",
        "image_size = 224\n",
        "\n",
        "train_transform = T.Compose(\n",
        "    [\n",
        "        T.Resize((image_size, image_size)),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.RandomRotation(10),\n",
        "        T.ColorJitter(\n",
        "            brightness=0.2,\n",
        "            contrast=0.2,\n",
        "            saturation=0.2,\n",
        "            hue=0.02,\n",
        "        ),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transform = T.Compose(\n",
        "    [\n",
        "        T.Resize((image_size, image_size)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = ReptiliaDataset(train_df, transform=train_transform)\n",
        "val_dataset = ReptiliaDataset(val_df, transform=val_transform)\n",
        "test_dataset = ReptiliaDataset(test_df, transform=val_transform)"
      ],
      "metadata": {
        "id": "A63C_fGYz163"
      },
      "id": "A63C_fGYz163",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5e) Dataloaders\n",
        "\n",
        "# Requested batch size:\n",
        "requested_batch_size = 64\n",
        "\n",
        "BATCH_SIZE = requested_batch_size\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        ")\n",
        "len(train_loader), len(val_loader), len(test_loader)\n"
      ],
      "metadata": {
        "id": "gwUDqT380G9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18e92d9-c91c-4ddc-e8b5-5430cd31e2b3"
      },
      "id": "gwUDqT380G9g",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(217, 31, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch import amp\n",
        "\n",
        "def create_warmup_scheduler(optimizer, warmup_steps: int):\n",
        "    \"\"\"\n",
        "    Linear warmup from 0 -> 1 over warmup_steps, then stays at 1.\n",
        "    \"\"\"\n",
        "    def lr_lambda(step: int):\n",
        "        if step < warmup_steps:\n",
        "            return float(step) / float(max(1, warmup_steps))\n",
        "        return 1.0\n",
        "\n",
        "    return LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    scheduler: Optional[LambdaLR],\n",
        "    epoch: int,\n",
        "    total_steps_done: int,\n",
        "    use_bf16: bool = True,\n",
        ") -> Tuple[int, float]:\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    # Check bf16 capability\n",
        "    can_bf16 = use_bf16 and torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
        "\n",
        "    scaler = amp.GradScaler(\"cuda\", enabled=not can_bf16)\n",
        "\n",
        "    for images, labels in tqdm(loader, desc=f\"Train Epoch {epoch}\"):\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        if can_bf16:\n",
        "\n",
        "            with amp.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "                outputs = model(images)\n",
        "                loss = nn.functional.cross_entropy(outputs, labels)\n",
        "        else:\n",
        "            # fp16 / default autocast on CUDA\n",
        "            with amp.autocast(\"cuda\"):\n",
        "                outputs = model(images)\n",
        "                loss = nn.functional.cross_entropy(outputs, labels)\n",
        "\n",
        "        # backward + step\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        n_batches += 1\n",
        "        total_steps_done += 1\n",
        "\n",
        "    avg_loss = running_loss / max(1, n_batches)\n",
        "    print(f\"Epoch {epoch} - Train Loss: {avg_loss:.4f}\")\n",
        "    return total_steps_done, avg_loss\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model: nn.Module, loader: DataLoader) -> Tuple[float, float]:\n",
        "    model.eval()\n",
        "    all_preds: List[int] = []\n",
        "    all_labels: List[int] = []\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for images, labels in tqdm(loader, desc=\"Eval\"):\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = nn.functional.cross_entropy(outputs, labels)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy().tolist())\n",
        "        all_labels.extend(labels.cpu().numpy().tolist())\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    avg_loss = total_loss / max(1, num_batches)\n",
        "    return acc, avg_loss"
      ],
      "metadata": {
        "id": "mi220Cyc0PsD"
      },
      "id": "mi220Cyc0PsD",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5g) Hyperparameters\n",
        "EPOCHS = 40\n",
        "LR = 0.0005\n",
        "WEIGHT_DECAY = 0.0004\n",
        "WARMUP_STEPS = 5000  # global steps"
      ],
      "metadata": {
        "id": "m-jwBQvZSKdZ"
      },
      "id": "m-jwBQvZSKdZ",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 - Model 1  - ResNet50 Baseline"
      ],
      "metadata": {
        "id": "voTRbqSxu72G"
      },
      "id": "voTRbqSxu72G"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.no_vertical_scroll()\n",
        "\n",
        "#@title ResNet50 Model\n",
        "\n",
        "\n",
        "# Build ResNet50 (using timm for consistency)\n",
        "model_resnet = timm.create_model(\n",
        "    \"resnet50\",\n",
        "    pretrained=True,\n",
        "    num_classes=num_classes,\n",
        ")\n",
        "model_resnet.to(device)\n",
        "\n",
        "optimizer_resnet = AdamW(\n",
        "    model_resnet.parameters(),\n",
        "    lr=LR,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        ")\n",
        "\n",
        "# Steps per epoch = batches in train loader\n",
        "steps_per_epoch = len(train_loader)\n",
        "total_training_steps = EPOCHS * steps_per_epoch\n",
        "print(\"Steps per epoch:\", steps_per_epoch)\n",
        "print(\"Total training steps:\", total_training_steps)\n",
        "\n",
        "scheduler_resnet = create_warmup_scheduler(\n",
        "    optimizer_resnet,\n",
        "    warmup_steps=WARMUP_STEPS,\n",
        ")\n",
        "\n",
        "history_resnet = {\"epoch\": [], \"val_acc\": [], \"val_loss\": [], \"train_loss\": []}\n",
        "\n",
        "global_step = 0\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    global_step, train_loss = train_one_epoch(\n",
        "        model_resnet,\n",
        "        train_loader,\n",
        "        optimizer_resnet,\n",
        "        scheduler_resnet,\n",
        "        epoch,\n",
        "        total_steps_done=global_step,\n",
        "        use_bf16=True,\n",
        "    )\n",
        "\n",
        "    val_acc, val_loss = evaluate(model_resnet, val_loader)\n",
        "    history_resnet[\"epoch\"].append(epoch)\n",
        "    history_resnet[\"val_acc\"].append(val_acc)\n",
        "    history_resnet[\"val_loss\"].append(val_loss)\n",
        "    history_resnet[\"train_loss\"].append(train_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch} - Val Accuracy: {val_acc:.4f} - Val Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "iB2brDGEvAU2"
      },
      "id": "iB2brDGEvAU2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "# Plot for ResNet50 (if history is available)\n",
        "if history_resnet[\"epoch\"]:\n",
        "    axes[1].plot(history_resnet[\"epoch\"], history_resnet[\"val_acc\"], label=\"ResNet50 Val Accuracy\")\n",
        "    axes[1].plot(history_resnet[\"epoch\"], history_resnet[\"train_loss\"], label=\"ResNet50 Train Loss\")\n",
        "    axes[1].plot(history_resnet[\"epoch\"], history_resnet[\"val_loss\"], label=\"ResNet50 Val Loss\")\n",
        "    axes[1].set_xlabel(\"Epoch\")\n",
        "    axes[1].set_ylabel(\"Accuracy/Loss\")\n",
        "    axes[1].set_title(\"ResNet50: Training and Validation Metrics\")\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "else:\n",
        "    axes[1].text(0.5, 0.5, \"ResNet50 training was interrupted.\", horizontalalignment='center', verticalalignment='center', transform=axes[1].transAxes, fontsize=12)\n",
        "    axes[1].set_title(\"ResNet50: Training and Validation Metrics\")\n",
        "    axes[1].set_xticks([])\n",
        "    axes[1].set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fGgznHip03rd"
      },
      "id": "fGgznHip03rd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "027bbacf",
        "outputId": "dc2ecb97-2606-45c5-f6ed-b39626a80c83"
      },
      "source": [
        "#@title Setup for TPU\n",
        "print(\"Installing torch_xla and torchvision...\")\n",
        "!pip install torch_xla torchvision -f https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla/torch_xla-*.whl\n",
        "\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch\n",
        "\n",
        "# Configure the device\n",
        "try:\n",
        "    # Attempt to get TPU device\n",
        "    device = xm.xla_device()\n",
        "    print(f\"Device: {device} (TPU)\")\n",
        "except RuntimeError:\n",
        "    # Fallback to CUDA if TPU is not available\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"Device: {device} (CUDA)\")\n",
        "    else:\n",
        "        # Fallback to CPU if neither TPU nor CUDA is available\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(f\"Device: {device} (CPU)\")\n",
        "\n",
        "# Verify device setup\n",
        "print(f\"Current device: {device}\")"
      ],
      "id": "027bbacf",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing torch_xla and torchvision...\n",
            "Looking in links: https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla/torch_xla-*.whl\n",
            "Requirement already satisfied: torch_xla in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from torch_xla) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_xla) (2.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from torch_xla) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_xla) (2.32.4)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.9.0+cpu)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (12.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2025.10.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_xla) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_xla) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_xla) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_xla) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1069258695.py:11: DeprecationWarning: Use torch_xla.device instead\n",
            "  device = xm.xla_device()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: xla:0 (TPU)\n",
            "Current device: xla:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "referenced_widgets": [
            "9fc2bf4ff3784513b272430095a52482",
            "95ddaad847c54e2aa76babd8f622cad8",
            "a6bf405f37fa40b084f529029d20d7a2",
            "5d77d696ef4d45ceb0be27c41dd6efce",
            "46f39d4ca7534495b037effc67173c8f",
            "c218f94fbfce4fcbaaafe374935c5a0e",
            "90dee09735934e8baa872f97b78242ba",
            "e507de15b8904c228a3ef06842449625",
            "aa2c4446316948f29724f40055aef667",
            "98a334cbe96d40259ac7582c9661d4f2",
            "e3967fe632434805904c0897961bf468"
          ]
        },
        "id": "2fe48d3c",
        "outputId": "726c671d-13e8-4c45-89e0-fac00c17d636"
      },
      "source": [
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.runtime as runtime # Added import for runtime\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import torch\n",
        "from torch import nn\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "!pip -q install timm\n",
        "import timm\n",
        "\n",
        "# Helper function\n",
        "def create_warmup_scheduler(optimizer, warmup_steps: int):\n",
        "    def lr_lambda(step: int):\n",
        "        if step < warmup_steps:\n",
        "            return float(step) / float(max(1, warmup_steps))\n",
        "        return 1.0\n",
        "    return LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "# Custom collate function to handle None values from __getitem__\n",
        "def collate_fn_skip_none(batch):\n",
        "    batch = list(filter(lambda x: x is not None, batch))\n",
        "    if not batch: # If the batch is empty after filtering\n",
        "        # Return empty tensors that can be handled by the training/eval loop\n",
        "        return torch.tensor([]), torch.tensor([])\n",
        "    return torch.utils.data.dataloader.default_collate(batch)\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 40\n",
        "LR = 0.0005\n",
        "WEIGHT_DECAY = 0.0004\n",
        "WARMUP_STEPS = 5000\n",
        "\n",
        "# Paths\n",
        "BASE_PATH = \"/content/drive/MyDrive/herpeton//data (1)/biotrove_train\"\n",
        "metadata_path = os.path.join(BASE_PATH, \"reptilia_dataset_processed.csv\")\n",
        "\n",
        "df = pd.read_csv(metadata_path)\n",
        "df[\"label_id\"], label_names = pd.factorize(df[\"species\"])\n",
        "num_classes = len(label_names)\n",
        "\n",
        "train_df = df[df[\"split\"] == \"train\"].copy()\n",
        "val_df = df[df[\"split\"] == \"val\"].copy()\n",
        "test_df = df[df[\"split\"] == \"test\"].copy()\n",
        "\n",
        "train_df = train_df.dropna(subset=['image_path_fixed']).reset_index(drop=True)\n",
        "val_df = val_df.dropna(subset=['image_path_fixed']).reset_index(drop=True)\n",
        "test_df = test_df.dropna(subset=['image_path_fixed']).reset_index(drop=True)\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image, UnidentifiedImageError # Import UnidentifiedImageError\n",
        "\n",
        "class ReptiliaDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row[\"image_path_fixed\"]\n",
        "        label = int(row[\"label_id\"])\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except (IOError, OSError, UnidentifiedImageError) as e: # Catch specific IO, OS, and image loading errors\n",
        "            print(f\"Error loading {img_path}: {e}. Skipping this sample.\", flush=True)\n",
        "            return None # Return None for problematic samples\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "image_size = 224\n",
        "\n",
        "train_transform = T.Compose([\n",
        "    T.Resize((image_size, image_size)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomRotation(10),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transform = T.Compose([\n",
        "    T.Resize((image_size, image_size)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "requested_batch_size = 64\n",
        "\n",
        "flags = {\n",
        "    \"EPOCHS\": EPOCHS,\n",
        "    \"LR\": LR,\n",
        "    \"WEIGHT_DECAY\": WEIGHT_DECAY,\n",
        "    \"WARMUP_STEPS\": WARMUP_STEPS,\n",
        "    \"num_classes\": num_classes,\n",
        "    \"train_df\": train_df,\n",
        "    \"val_df\": val_df,\n",
        "    \"test_df\": test_df,\n",
        "    \"train_transform\": train_transform,\n",
        "    \"val_transform\": val_transform,\n",
        "    \"ReptiliaDataset\": ReptiliaDataset,\n",
        "    \"requested_batch_size\": requested_batch_size,\n",
        "    \"create_warmup_scheduler\": create_warmup_scheduler,\n",
        "    \"collate_fn_skip_none\": collate_fn_skip_none, # Pass the collate_fn to flags\n",
        "}\n",
        "\n",
        "def _mp_fn(index, flags):\n",
        "    EPOCHS = flags[\"EPOCHS\"]\n",
        "    LR = flags[\"LR\"]\n",
        "    WEIGHT_DECAY = flags[\"WEIGHT_DECAY\"]\n",
        "    WARMUP_STEPS = flags[\"WARMUP_STEPS\"]\n",
        "    num_classes = flags[\"num_classes\"]\n",
        "    train_df = flags[\"train_df\"]\n",
        "    val_df = flags[\"val_df\"]\n",
        "    test_df = flags[\"test_df\"]\n",
        "    train_transform = flags[\"train_transform\"]\n",
        "    val_transform = flags[\"val_transform\"]\n",
        "    ReptiliaDataset = flags[\"ReptiliaDataset\"]\n",
        "    BATCH_SIZE_PER_CORE = flags[\"requested_batch_size\"]\n",
        "    create_warmup_scheduler = flags[\"create_warmup_scheduler\"]\n",
        "    collate_fn_skip_none = flags[\"collate_fn_skip_none\"]\n",
        "\n",
        "    device = xm.xla_device()\n",
        "    print(f\"[{index}] Device: {device}\")\n",
        "\n",
        "    xm.rendezvous(\"init_dist_resnet_tpu\")\n",
        "\n",
        "    train_dataset = ReptiliaDataset(train_df, transform=train_transform)\n",
        "    val_dataset = ReptiliaDataset(val_df, transform=val_transform)\n",
        "    test_dataset = ReptiliaDataset(test_df, transform=val_transform)\n",
        "\n",
        "    # Use pl.MpDeviceLoader from parallel_loader\n",
        "    train_loader = pl.MpDeviceLoader(\n",
        "        DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=BATCH_SIZE_PER_CORE,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            drop_last=False, # Changed to False to allow collate_fn to handle uneven batches\n",
        "            collate_fn=collate_fn_skip_none # Add custom collate_fn\n",
        "        ),\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    val_loader = pl.MpDeviceLoader(\n",
        "        DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=BATCH_SIZE_PER_CORE,\n",
        "            shuffle=False,\n",
        "            num_workers=0,\n",
        "            drop_last=False,\n",
        "            collate_fn=collate_fn_skip_none # Add custom collate_fn\n",
        "        ),\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    test_loader = pl.MpDeviceLoader(\n",
        "        DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=BATCH_SIZE_PER_CORE,\n",
        "            shuffle=False,\n",
        "            num_workers=0,\n",
        "            drop_last=False,\n",
        "            collate_fn=collate_fn_skip_none # Add custom collate_fn\n",
        "        ),\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    if runtime.global_ordinal() == 0: # Changed xm.get_ordinal() to runtime.global_ordinal()\n",
        "        print(f\"[{index}] Dataloader batches (per core): Train={len(train_loader)}, Val={len(val_loader)}, Test={len(test_loader)}\")\n",
        "\n",
        "    def train_one_epoch_xla(model, loader, optimizer, scheduler, epoch, total_steps_done, device, use_bf16=True):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        n_batches = 0\n",
        "\n",
        "        # MpDeviceLoader handles device placement; iterate directly\n",
        "        for images, labels in tqdm(loader, desc=f\"[{index}] Train Epoch {epoch}\", disable=(runtime.global_ordinal() != 0)): # Changed xm.get_ordinal()\n",
        "            if images.numel() == 0: # Skip if batch is empty\n",
        "                continue\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            outputs = model(images)\n",
        "            loss = nn.functional.cross_entropy(outputs, labels)\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer)\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            n_batches += 1\n",
        "            total_steps_done += 1\n",
        "\n",
        "        reduced_running_loss = xm.mesh_reduce('train_loss_reduce', running_loss, np.sum)\n",
        "        reduced_n_batches = xm.mesh_reduce('train_batches_reduce', n_batches, np.sum)\n",
        "        avg_loss = reduced_running_loss / max(1, reduced_n_batches)\n",
        "\n",
        "        if runtime.global_ordinal() == 0: # Changed xm.get_ordinal()\n",
        "            print(f\"Epoch {epoch} - Train Loss: {avg_loss:.4f}\")\n",
        "        return total_steps_done, avg_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate_xla(model, loader, device):\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        for images, labels in tqdm(loader, desc=f\"[{index}] Eval\", disable=(runtime.global_ordinal() != 0)): # Changed xm.get_ordinal()\n",
        "            if images.numel() == 0: # Skip if batch is empty\n",
        "                continue\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = nn.functional.cross_entropy(outputs, labels)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy().tolist())\n",
        "            all_labels.extend(labels.cpu().numpy().tolist())\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        reduced_total_loss = xm.mesh_reduce(\"eval_loss_reduce\", total_loss, np.sum)\n",
        "        reduced_num_batches = xm.mesh_reduce(\"eval_batches_reduce\", num_batches, np.sum)\n",
        "\n",
        "        all_preds_tensor = torch.tensor(all_preds, device=device)\n",
        "        all_labels_tensor = torch.tensor(all_labels, device=device)\n",
        "        global_all_preds = xmp.all_gather(all_preds_tensor).cpu().numpy()\n",
        "        global_all_labels = xmp.all_gather(all_labels_tensor).cpu().numpy()\n",
        "\n",
        "        acc = accuracy_score(global_all_labels, global_all_preds)\n",
        "        avg_loss = reduced_total_loss / max(1, reduced_num_batches)\n",
        "        return acc, avg_loss\n",
        "\n",
        "    model = timm.create_model(\"resnet50\", pretrained=True, num_classes=num_classes)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = create_warmup_scheduler(optimizer, warmup_steps=WARMUP_STEPS)\n",
        "\n",
        "    history = {\"epoch\": [], \"val_acc\": [], \"val_loss\": [], \"train_loss\": []}\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        global_step, train_loss = train_one_epoch_xla(\n",
        "            model, train_loader, optimizer, scheduler, epoch, total_steps_done=global_step, device=device, use_bf16=True\n",
        "        )\n",
        "        val_acc, val_loss = evaluate_xla(model, val_loader, device)\n",
        "\n",
        "        history[\"epoch\"].append(epoch)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "\n",
        "        if runtime.global_ordinal() == 0: # Changed xm.get_ordinal()\n",
        "            print(f\"Epoch {epoch} - Val Accuracy: {val_acc:.4f} - Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    if runtime.global_ordinal() == 0: # Changed xm.get_ordinal()\n",
        "        return history\n",
        "\n",
        "print(\"Launching ResNet50 training on TPU cores...\")\n",
        "history_resnet_tpu = xmp.spawn(_mp_fn, args=(flags,), nprocs=len(xm.get_xla_supported_devices()))\n",
        "print(\"TPU training complete.\")"
      ],
      "id": "2fe48d3c",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching ResNet50 training on TPU cores...\n",
            "[0] Device: xla:0\n",
            "[0] Dataloader batches (per core): Train=217, Val=31, Test=28\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3266343034.py:137: DeprecationWarning: Use torch_xla.device instead\n",
            "  device = xm.xla_device()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fc2bf4ff3784513b272430095a52482",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[0] Train Epoch 1:   0%|          | 0/217 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "BivlapWQZHIW"
      },
      "id": "BivlapWQZHIW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V6E1",
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9fc2bf4ff3784513b272430095a52482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95ddaad847c54e2aa76babd8f622cad8",
              "IPY_MODEL_a6bf405f37fa40b084f529029d20d7a2",
              "IPY_MODEL_5d77d696ef4d45ceb0be27c41dd6efce"
            ],
            "layout": "IPY_MODEL_46f39d4ca7534495b037effc67173c8f"
          }
        },
        "95ddaad847c54e2aa76babd8f622cad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c218f94fbfce4fcbaaafe374935c5a0e",
            "placeholder": "​",
            "style": "IPY_MODEL_90dee09735934e8baa872f97b78242ba",
            "value": "[0] Train Epoch 1:   0%"
          }
        },
        "a6bf405f37fa40b084f529029d20d7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e507de15b8904c228a3ef06842449625",
            "max": 217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa2c4446316948f29724f40055aef667",
            "value": 0
          }
        },
        "5d77d696ef4d45ceb0be27c41dd6efce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a334cbe96d40259ac7582c9661d4f2",
            "placeholder": "​",
            "style": "IPY_MODEL_e3967fe632434805904c0897961bf468",
            "value": " 0/217 [00:00&lt;?, ?it/s]"
          }
        },
        "46f39d4ca7534495b037effc67173c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c218f94fbfce4fcbaaafe374935c5a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90dee09735934e8baa872f97b78242ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e507de15b8904c228a3ef06842449625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa2c4446316948f29724f40055aef667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98a334cbe96d40259ac7582c9661d4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3967fe632434805904c0897961bf468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}