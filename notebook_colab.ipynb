{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omarsagoo/herpeton/blob/Carrie/notebook_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Colab Friendly Notebook"
      ],
      "metadata": {
        "id": "acgPwAwdYa4B"
      },
      "id": "acgPwAwdYa4B"
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B3Iu6JjMQZx3",
        "outputId": "00d56b9b-583f-4cc7-fc78-9e32b035e0fa"
      },
      "id": "B3Iu6JjMQZx3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arbor-process (from -r /content/requirements.txt (line 4))\n",
            "  Downloading arbor_process-0.1.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 9)) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 12)) (11.3.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 13)) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 16)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 17)) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 20)) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.28.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 23)) (2.32.4)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 26)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 27)) (0.23.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 28)) (4.57.1)\n",
            "Collecting jupyter>=1.0.0 (from -r /content/requirements.txt (line 31))\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.6.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 32)) (7.7.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 35)) (1.6.1)\n",
            "Requirement already satisfied: imageio>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 36)) (2.37.2)\n",
            "Requirement already satisfied: nest_asyncio>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 37)) (1.6.0)\n",
            "Collecting aiohttp==3.9.5 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading aiohttp-3.9.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting aiosignal==1.3.1 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting async-timeout==4.0.3 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting attrs==23.2.0 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting contourpy==1.2.1 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading contourpy-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting cramjam==2.8.3 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading cramjam-2.8.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (0.12.1)\n",
            "Collecting fastparquet==2024.5.0 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading fastparquet-2024.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting fonttools==4.53.0 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading fonttools-4.53.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.2/162.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist==1.4.1 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting fsspec==2024.6.0 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting idna==3.7 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting importlib-resources==6.4.0 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting kiwisolver==1.4.5 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading kiwisolver-1.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting matplotlib>=3.5.0 (from -r /content/requirements.txt (line 16))\n",
            "  Downloading matplotlib-3.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting multidict==6.0.5 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading multidict-6.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting numpy>=1.21.0 (from -r /content/requirements.txt (line 9))\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==24.1 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pillow>=9.0.0 (from -r /content/requirements.txt (line 12))\n",
            "  Downloading pillow-10.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pyarrow==16.1.0 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading pyarrow-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyparsing==3.1.2 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from arbor-process->-r /content/requirements.txt (line 4)) (2.9.0.post0)\n",
            "Collecting pytz==2024.1 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting six==1.16.0 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tqdm>=4.64.0 (from -r /content/requirements.txt (line 20))\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata==2024.1 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting yarl==1.9.4 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading yarl-1.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting zipp==3.19.2 (from arbor-process->-r /content/requirements.txt (line 4))\n",
            "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (3.20.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r /content/requirements.txt (line 7)) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python>=4.5.0 (from -r /content/requirements.txt (line 13))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->-r /content/requirements.txt (line 23)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->-r /content/requirements.txt (line 23)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.28.0->-r /content/requirements.txt (line 23)) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->-r /content/requirements.txt (line 26)) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.20.0->-r /content/requirements.txt (line 28)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.20.0->-r /content/requirements.txt (line 28)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.20.0->-r /content/requirements.txt (line 28)) (0.6.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (6.17.1)\n",
            "Collecting jupyterlab (from jupyter>=1.0.0->-r /content/requirements.txt (line 31))\n",
            "  Downloading jupyterlab-4.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (3.0.16)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->-r /content/requirements.txt (line 35)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->-r /content/requirements.txt (line 35)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->-r /content/requirements.txt (line 35)) (3.6.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets>=2.14.0->-r /content/requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (6.5.1)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (4.9.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.12.0->-r /content/requirements.txt (line 26)) (1.3.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (25.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (5.9.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (5.10.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.3.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.5.1)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31))\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.28.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31))\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.14.0)\n",
            "Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31))\n",
            "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.6.1->notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (4.5.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.9.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (25.1.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31))\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (4.25.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.21.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.6.0->-r /content/requirements.txt (line 32)) (0.2.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.3.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.28.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (4.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (0.1.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (2.23)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r /content/requirements.txt (line 31)) (1.4.0)\n",
            "Downloading arbor_process-0.1.1-py3-none-any.whl (16 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m133.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.9.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.2/309.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cramjam-2.8.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastparquet-2024.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fonttools-4.53.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Downloading kiwisolver-1.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jupyterlab-4.5.0-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: pytz, zipp, tzdata, tqdm, six, pyparsing, pillow, packaging, numpy, multidict, kiwisolver, json5, jedi, importlib-resources, idna, fsspec, frozenlist, fonttools, cramjam, attrs, async-timeout, async-lru, yarl, pyarrow, opencv-python, contourpy, aiosignal, matplotlib, aiohttp, fastparquet, arbor-process, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.23.0\n",
            "    Uninstalling zipp-3.23.0:\n",
            "      Successfully uninstalled zipp-3.23.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.5\n",
            "    Uninstalling pyparsing-3.2.5:\n",
            "      Successfully uninstalled pyparsing-3.2.5\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.7.0\n",
            "    Uninstalling multidict-6.7.0:\n",
            "      Successfully uninstalled multidict-6.7.0\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.9\n",
            "    Uninstalling kiwisolver-1.4.9:\n",
            "      Successfully uninstalled kiwisolver-1.4.9\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib_resources 6.5.2\n",
            "    Uninstalling importlib_resources-6.5.2:\n",
            "      Successfully uninstalled importlib_resources-6.5.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.8.0\n",
            "    Uninstalling frozenlist-1.8.0:\n",
            "      Successfully uninstalled frozenlist-1.8.0\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.60.1\n",
            "    Uninstalling fonttools-4.60.1:\n",
            "      Successfully uninstalled fonttools-4.60.1\n",
            "  Attempting uninstall: cramjam\n",
            "    Found existing installation: cramjam 2.11.0\n",
            "    Uninstalling cramjam-2.11.0:\n",
            "      Successfully uninstalled cramjam-2.11.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.4.0\n",
            "    Uninstalling attrs-25.4.0:\n",
            "      Successfully uninstalled attrs-25.4.0\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.22.0\n",
            "    Uninstalling yarl-1.22.0:\n",
            "      Successfully uninstalled yarl-1.22.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.3.3\n",
            "    Uninstalling contourpy-1.3.3:\n",
            "      Successfully uninstalled contourpy-1.3.3\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.13.2\n",
            "    Uninstalling aiohttp-3.13.2:\n",
            "      Successfully uninstalled aiohttp-3.13.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "db-dtypes 1.4.4 requires packaging>=24.2.0, but you have packaging 24.1 which is incompatible.\n",
            "importlib-metadata 8.7.0 requires zipp>=3.20, but you have zipp 3.19.2 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-bigquery 3.38.0 requires packaging>=24.2.0, but you have packaging 24.1 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.9.5 aiosignal-1.3.1 arbor-process-0.1.1 async-lru-2.0.5 async-timeout-4.0.3 attrs-23.2.0 contourpy-1.2.1 cramjam-2.8.3 fastparquet-2024.5.0 fonttools-4.53.0 frozenlist-1.4.1 fsspec-2024.6.0 idna-3.7 importlib-resources-6.4.0 jedi-0.19.2 json5-0.12.1 jupyter-1.1.1 jupyter-lsp-2.3.0 jupyterlab-4.5.0 jupyterlab-server-2.28.0 kiwisolver-1.4.5 matplotlib-3.9.0 multidict-6.0.5 numpy-1.26.4 opencv-python-4.11.0.86 packaging-24.1 pillow-10.3.0 pyarrow-16.1.0 pyparsing-3.1.2 pytz-2024.1 six-1.16.0 tqdm-4.66.4 tzdata-2024.1 yarl-1.9.4 zipp-3.19.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "packaging",
                  "pyparsing",
                  "six"
                ]
              },
              "id": "2111066744734f098d588701d5e5301b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Environment Setup\n",
        "import hashlib\n",
        "import io\n",
        "import os\n",
        "import sys\n",
        "from collections import Counter, defaultdict\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Iterable, Optional, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Install third-party packages if missing (Colab-friendly)\n",
        "try:\n",
        "    from datasets import load_dataset\n",
        "except ImportError:\n",
        "    !pip -q install datasets\n",
        "    from datasets import load_dataset\n",
        "\n",
        "try:\n",
        "    import imagehash\n",
        "except ImportError:\n",
        "    !pip -q install ImageHash\n",
        "    import imagehash"
      ],
      "metadata": {
        "id": "P5JEs1ktYJVr"
      },
      "id": "P5JEs1ktYJVr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive\n",
        "CURATE_TO_DRIVE = True\n",
        "\n",
        "if CURATE_TO_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_OUT = \"/content/drive/MyDrive/herpeton\"\n",
        "else:\n",
        "    BASE_OUT = \"/content/herpeton\"\n",
        "\n",
        "os.makedirs(BASE_OUT, exist_ok=True)\n",
        "\n",
        "# Controls to keep runtime reasonable\n",
        "MAX_RECORDS = 15000          # hard cap across the stream (increase if you have time/compute)\n",
        "SAMPLE_PER_SPECIES = 120     # images per species to collect/curate/EDA\n",
        "REPORT_DIR = os.path.join(BASE_OUT, \"_reports\")\n",
        "os.makedirs(REPORT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Output base: {BASE_OUT}\")\n",
        "print(f\"Reports   : {REPORT_DIR}\")\n",
        "print(f\"Limits    : MAX_RECORDS={MAX_RECORDS}, SAMPLE_PER_SPECIES={SAMPLE_PER_SPECIES}\")"
      ],
      "metadata": {
        "id": "jEsm8rUUYW-3"
      },
      "id": "jEsm8rUUYW-3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YNGhBrXeYIZF"
      },
      "id": "YNGhBrXeYIZF"
    },
    {
      "cell_type": "code",
      "source": [
        "python quick_start.py"
      ],
      "metadata": {
        "id": "W6XYfcohQi0c"
      },
      "id": "W6XYfcohQi0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "639411f7",
      "metadata": {
        "id": "639411f7"
      },
      "source": [
        "## Step 1: Extract Reptilia Metadata from BioTrove\n",
        "\n",
        "Using HuggingFace's efficient filter() method to extract only Reptilia samples from the 135M sample dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7795bf7f",
      "metadata": {
        "id": "7795bf7f"
      },
      "outputs": [],
      "source": [
        "def extract_reptilia_efficient():\n",
        "    \"\"\"\n",
        "    Efficiently extract Reptilia samples using HuggingFace datasets with filtering.\n",
        "    Since Reptilia exists in the dataset but is distributed throughout 135M samples,\n",
        "    the dataset's built-in filtering capabilities are used.\n",
        "    \"\"\"\n",
        "    from datasets import load_dataset\n",
        "    from tqdm.auto import tqdm\n",
        "\n",
        "    print(\"EFFICIENT REPTILIA EXTRACTION\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Using filter() to extract only Reptilia class\")\n",
        "\n",
        "\n",
        "    # Load dataset in streaming mode\n",
        "    print(\"Loading BioTrove-Train dataset...\")\n",
        "    dataset = load_dataset('BGLab/BioTrove-Train', streaming=True, split='train')\n",
        "\n",
        "    # Filter for Reptilia class\n",
        "    print(\"Applying Reptilia filter...\")\n",
        "    reptilia_dataset = dataset.filter(lambda example: example['class'] == 'Reptilia')\n",
        "\n",
        "    print(\"Extracting Reptilia samples...\")\n",
        "    reptilia_samples = []\n",
        "\n",
        "    pbar = tqdm(desc=\"Collecting Reptilia\", unit=\" samples\")\n",
        "\n",
        "    # Collect samples\n",
        "    target_samples = 2000  # Collect 2000 Reptilia samples\n",
        "\n",
        "    for idx, item in enumerate(reptilia_dataset):\n",
        "        reptilia_samples.append(item)\n",
        "\n",
        "        if idx < 10:  # Show first 10\n",
        "            print(f\"\\n   Sample {idx+1}:\")\n",
        "            print(f\"      scientificName: {item.get('scientificName', 'Unknown')}\")\n",
        "            print(f\"      family: {item.get('family', 'Unknown')}\")\n",
        "            print(f\"      order: {item.get('order', 'Unknown')}\")\n",
        "\n",
        "        pbar.update(1)\n",
        "        pbar.set_description(f\"Collected {len(reptilia_samples)} Reptilia\")\n",
        "\n",
        "        if len(reptilia_samples) >= target_samples:\n",
        "            print(f\"\\n   Reached target of {target_samples} samples\")\n",
        "            break\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EXTRACTION COMPLETE:\")\n",
        "    print(f\"   Total Reptilia samples collected: {len(reptilia_samples)}\")\n",
        "\n",
        "    if reptilia_samples:\n",
        "        # Save to parquet chunks\n",
        "        os.makedirs(\"biotrove_metadata\", exist_ok=True)\n",
        "        chunk_size = 250\n",
        "        saved_files = []\n",
        "\n",
        "        print(f\"\\n   Saving {len(reptilia_samples)} samples in chunks of {chunk_size}...\")\n",
        "\n",
        "        for i in range(0, len(reptilia_samples), chunk_size):\n",
        "            chunk_data = reptilia_samples[i:i+chunk_size]\n",
        "            chunk_df = pd.DataFrame(chunk_data)\n",
        "\n",
        "            chunk_filename = f\"biotrove_metadata/reptilia_chunk_{i//chunk_size}.parquet\"\n",
        "            chunk_df.to_parquet(chunk_filename, index=False)\n",
        "            saved_files.append(chunk_filename)\n",
        "\n",
        "            print(f\"      Chunk {i//chunk_size}: {len(chunk_data)} samples -> {chunk_filename}\")\n",
        "\n",
        "        print(f\"\\n   ✓ Saved {len(saved_files)} parquet files\")\n",
        "\n",
        "        # Show species diversity\n",
        "        species_list = [s.get('scientificName', 'Unknown') for s in reptilia_samples]\n",
        "        unique_species = set(species_list)\n",
        "        print(f\"   ✓ {len(unique_species)} unique species\")\n",
        "\n",
        "        # Show top families\n",
        "        families = [s.get('family', 'Unknown') for s in reptilia_samples]\n",
        "        from collections import Counter\n",
        "        top_families = Counter(families).most_common(10)\n",
        "        print(f\"\\n   Top 10 families:\")\n",
        "        for family, count in top_families:\n",
        "            print(f\"      {family}: {count} samples\")\n",
        "\n",
        "        return {\n",
        "            'samples': reptilia_samples,\n",
        "            'saved_files': saved_files,\n",
        "            'unique_species': len(unique_species)\n",
        "        }\n",
        "    else:\n",
        "        print(\"   ✗ No Reptilia samples found\")\n",
        "        return None\n",
        "\n",
        "# Run the efficient extraction\n",
        "reptilia_data = extract_reptilia_efficient()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6522339e",
      "metadata": {
        "id": "6522339e"
      },
      "source": [
        "## Step 2: Verify Extracted Data\n",
        "\n",
        "Check the extracted Reptilia samples before processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb4e775",
      "metadata": {
        "id": "abb4e775",
        "outputId": "6b3d1a5f-9306-48a7-b24d-080c1be3fed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VERIFICATION: Extracted Reptilia Data\n",
            "============================================================\n",
            "Found 0 parquet chunk files:\n",
            "\n",
            "Loading all Reptilia data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2033660690.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nLoading all Reptilia data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mall_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mreptilia_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTOTAL REPTILIA DATASET:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# Verify the extracted Reptilia data\n",
        "import glob\n",
        "\n",
        "print(\"VERIFICATION: Extracted Reptilia Data\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Find all reptilia chunk files\n",
        "chunk_files = sorted(glob.glob(\"biotrove_metadata/reptilia_chunk_*.parquet\"))\n",
        "\n",
        "print(f\"Found {len(chunk_files)} parquet chunk files:\")\n",
        "for file in chunk_files:\n",
        "    df = pd.read_parquet(file)\n",
        "    print(f\"   {file}: {len(df)} samples\")\n",
        "\n",
        "# Load all chunks\n",
        "print(\"\\nLoading all Reptilia data...\")\n",
        "all_dfs = [pd.read_parquet(f) for f in chunk_files]\n",
        "reptilia_df = pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "print(f\"\\nTOTAL REPTILIA DATASET:\")\n",
        "print(f\"   Total samples: {len(reptilia_df):,}\")\n",
        "print(f\"   Unique species: {reptilia_df['scientificName'].nunique()}\")\n",
        "print(f\"   Unique families: {reptilia_df['family'].nunique()}\")\n",
        "print(f\"   Unique orders: {reptilia_df['order'].nunique()}\")\n",
        "\n",
        "print(f\"\\nCOLUMNS:\")\n",
        "print(f\"   {list(reptilia_df.columns)}\")\n",
        "\n",
        "print(f\"\\nORDER DISTRIBUTION:\")\n",
        "order_counts = reptilia_df['order'].value_counts()\n",
        "for order, count in order_counts.items():\n",
        "    print(f\"   {order}: {count} samples ({count/len(reptilia_df)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nTOP 15 SPECIES:\")\n",
        "species_counts = reptilia_df['scientificName'].value_counts().head(15)\n",
        "for species, count in species_counts.items():\n",
        "    family = reptilia_df[reptilia_df['scientificName'] == species]['family'].iloc[0]\n",
        "    print(f\"   {species:<40} ({family:<20}): {count} samples\")\n",
        "\n",
        "print(f\"\\nFIRST 3 SAMPLE ROWS:\")\n",
        "print(reptilia_df.head(3).to_string(index=False))\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"✓ Reptilia dataset successfully extracted and verified!\")\n",
        "print(\"✓ Ready for BioTrove processing pipeline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f89dac30",
      "metadata": {
        "id": "f89dac30"
      },
      "source": [
        "## Step 3: Download Images and Create Dataset\n",
        "\n",
        "Download images from URLs and create ML-ready dataset with image-text pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11c4cdac",
      "metadata": {
        "id": "11c4cdac"
      },
      "outputs": [],
      "source": [
        "# Install arbor_process library for BioTrove processing\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import arbor_process\n",
        "    print(\"arbor_process is already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing arbor_process library...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"arbor-process\"])\n",
        "    import arbor_process\n",
        "    print(\"Successfully installed arbor_process\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64aea5b1",
      "metadata": {
        "id": "64aea5b1"
      },
      "outputs": [],
      "source": [
        "# Download Reptilia images from metadata URLs\n",
        "import os\n",
        "import glob\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "print(\"REPTILIA IMAGE DOWNLOAD\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(\"biotrove_processed\", exist_ok=True)\n",
        "os.makedirs(\"biotrove_processed/images\", exist_ok=True)\n",
        "\n",
        "# Load all Reptilia chunks\n",
        "chunk_files = sorted(glob.glob(\"biotrove_metadata/reptilia_chunk_*.parquet\"))\n",
        "print(f\"Loading {len(chunk_files)} Reptilia parquet chunks...\")\n",
        "\n",
        "all_chunks = [pd.read_parquet(f) for f in chunk_files]\n",
        "reptilia_metadata = pd.concat(all_chunks, ignore_index=True)\n",
        "\n",
        "print(f\"Total Reptilia samples: {len(reptilia_metadata):,}\")\n",
        "print(f\"Unique species: {reptilia_metadata['scientificName'].nunique()}\")\n",
        "\n",
        "# Save combined metadata\n",
        "metadata_path = \"biotrove_processed/reptilia_metadata.csv\"\n",
        "reptilia_metadata.to_csv(metadata_path, index=False)\n",
        "print(f\"\\nSaved combined metadata to: {metadata_path}\")\n",
        "\n",
        "def download_image(row):\n",
        "    \"\"\"Download a single image from URL\"\"\"\n",
        "    photo_id = row['photo_id']\n",
        "    \"\"\"Download single image from URL\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(photo_url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Open and verify image\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "\n",
        "        # Save image\n",
        "        img_filename = f\"biotrove_processed/images/{photo_id}.jpg\"\n",
        "        img.convert('RGB').save(img_filename, 'JPEG', quality=95)\n",
        "\n",
        "        return {'photo_id': photo_id, 'status': 'success', 'path': img_filename}\n",
        "    except Exception as e:\n",
        "        return {'photo_id': photo_id, 'status': 'failed', 'error': str(e)}\n",
        "\n",
        "# Download images with parallel processing\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DOWNLOADING IMAGES\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Downloading {len(reptilia_metadata)} images with 4 parallel workers...\")\n",
        "\n",
        "successful_downloads = []\n",
        "failed_downloads = []\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    # Submit all download tasks\n",
        "    futures = {executor.submit(download_image, row): idx\n",
        "               for idx, row in reptilia_metadata.iterrows()}\n",
        "\n",
        "    # Process completed downloads with progress bar\n",
        "    with tqdm(total=len(futures), desc=\"Downloading\") as pbar:\n",
        "        for future in as_completed(futures):\n",
        "            result = future.result()\n",
        "\n",
        "            if result['status'] == 'success':\n",
        "                successful_downloads.append(result)\n",
        "            else:\n",
        "                failed_downloads.append(result)\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_description(f\"Downloaded: {len(successful_downloads)}, Failed: {len(failed_downloads)}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"DOWNLOAD COMPLETE!\")\n",
        "print(f\"  Successfully downloaded: {len(successful_downloads)} images\")\n",
        "print(f\"  Failed downloads: {len(failed_downloads)} images\")\n",
        "print(f\"  Success rate: {len(successful_downloads)/len(reptilia_metadata)*100:.1f}%\")\n",
        "\n",
        "# Create image-text pairs dataset\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATING IMAGE-TEXT PAIRS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "successful_photo_ids = [d['photo_id'] for d in successful_downloads]\n",
        "successful_metadata = reptilia_metadata[reptilia_metadata['photo_id'].isin(successful_photo_ids)].copy()\n",
        "\n",
        "# Add image paths\n",
        "successful_metadata['image_path'] = successful_metadata['photo_id'].apply(\n",
        "    lambda x: f\"biotrove_processed/images/{x}.jpg\"\n",
        ")\n",
        "\n",
        "# Create text descriptions\n",
        "successful_metadata['text_description'] = successful_metadata.apply(\n",
        "    lambda row: f\"{row['scientificName']} ({row['common_name']}) - {row['family']}, Order {row['order']}, Class Reptilia\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Save final dataset\n",
        "final_dataset_path = \"biotrove_processed/reptilia_dataset_final.csv\"\n",
        "successful_metadata.to_csv(final_dataset_path, index=False)\n",
        "\n",
        "print(f\"Created {len(successful_metadata)} image-text pairs\")\n",
        "print(f\"Saved to: {final_dataset_path}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"PROCESSING COMPLETE!\")\n",
        "print(f\"  Metadata: {metadata_path}\")\n",
        "print(f\"  Images: biotrove_processed/images/ ({len(successful_downloads)} files)\")\n",
        "print(f\"  Final dataset: {final_dataset_path}\")\n",
        "print(f\"  Dataset ready for computer vision training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d0f896",
      "metadata": {
        "id": "30d0f896"
      },
      "outputs": [],
      "source": [
        "# Explore the processed dataset\n",
        "import random\n",
        "\n",
        "print(\"PROCESSED DATASET EXPLORATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check directory structure\n",
        "print(\"\\nDirectory structure:\")\n",
        "for root, dirs, files in os.walk(\"biotrove_processed\"):\n",
        "    level = root.replace(\"biotrove_processed\", \"\").count(os.sep)\n",
        "    indent = \" \" * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = \" \" * 2 * (level + 1)\n",
        "    for file in files[:5]:  # Show first 5 files\n",
        "        print(f\"{subindent}{file}\")\n",
        "    if len(files) > 5:\n",
        "        print(f\"{subindent}... and {len(files)-5} more files\")\n",
        "\n",
        "# Load processed metadata\n",
        "if os.path.exists(\"biotrove_processed/metadata.csv\"):\n",
        "    processed_df = pd.read_csv(\"biotrove_processed/metadata.csv\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"PROCESSED DATASET STATISTICS:\")\n",
        "    print(f\"  Total samples: {len(processed_df):,}\")\n",
        "    print(f\"  Unique species: {processed_df['scientificName'].nunique()}\")\n",
        "    print(f\"  Unique families: {processed_df['family'].nunique()}\")\n",
        "    print(f\"  Unique orders: {processed_df['order'].nunique()}\")\n",
        "\n",
        "    print(f\"\\nOrder distribution:\")\n",
        "    for order, count in processed_df['order'].value_counts().items():\n",
        "        print(f\"  {order}: {count} samples ({count/len(processed_df)*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nTop 10 species:\")\n",
        "    for species, count in processed_df['scientificName'].value_counts().head(10).items():\n",
        "        print(f\"  {species}: {count} samples\")\n",
        "\n",
        "    # Show sample images if available\n",
        "    image_dir = \"biotrove_processed/images\"\n",
        "    if os.path.exists(image_dir):\n",
        "        image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if image_files:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Sample images available: {len(image_files)}\")\n",
        "\n",
        "            # Display a few random samples\n",
        "            sample_images = random.sample(image_files, min(3, len(image_files)))\n",
        "            print(f\"\\nDisplaying {len(sample_images)} random samples...\")\n",
        "\n",
        "            for img_file in sample_images:\n",
        "                img_path = os.path.join(image_dir, img_file)\n",
        "                # Get metadata for this image\n",
        "                img_id = os.path.splitext(img_file)[0]\n",
        "                if img_id.isdigit():\n",
        "                    sample_info = processed_df[processed_df['photo_id'] == int(img_id)]\n",
        "                    if not sample_info.empty:\n",
        "                        print(f\"\\n  Image: {img_file}\")\n",
        "                        print(f\"    Species: {sample_info.iloc[0]['scientificName']}\")\n",
        "                        print(f\"    Family: {sample_info.iloc[0]['family']}\")\n",
        "                        print(f\"    Common name: {sample_info.iloc[0].get('common_name', 'N/A')}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Dataset ready for computer vision training.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}